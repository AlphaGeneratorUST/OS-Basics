Python Numba的基本用法
Python太动态了，事先编译一下静态一点
LLVM compiler: language-independent intermediate representation, written in C++， compile-time, link-time, run-time and "idle-time" optimization
核心应用领域：math-heavy, array-oriented，加快面向数组的计算
只能使用numpy和标准库的函数来加快numba速度
可以将pandas中处理数据的for循环作为单独的函数提出来，再使用Numba加速
Numba库提供的是一种懒编译（Lazy Compilation）技术，用到的时候才编译
Python速度慢的另一个重要原因是变量类型不确定，需要解释器进行大量的类型推断，对此Numba给出了Eager Compilation的优化技术
Numba使用了LLVM和NVVM技术，将Python、Julia这样的解释语言直接翻译成CPU或GPU可执行的机器码
Cython
Numba

1）使用jit加速Python低效的for语句：
numba不支持list comprehensions，但支持dict, set or generator comprehensions
import numba as nb
@nb.jit(nopython=True)

2) 使用vectorize实现numpy的ufunc功能: vectorize装饰器将函数向量化，变成类似NumPy函数一样，直接处理矩阵和张量
@nb.vectorize(nopython=True)
vectorize下的函数所接受的参数都是一个个的数，而不是整个数组
可以显示地定义函数的参数类型：
@nb.vectorize("float32(float32, int32)", nopython=True)
@nb.vectorize([
    "float32(float32, int32)",
    "float32(float32, float32)"
    ], nopython=True)

vectorize可以“并行”：参数target一共有三种取值（cpu/parallel/cuda）, 1KB, 1MB, >1MB
@nb.vectorize("float32(float32, float32)", target="parellel", nopython=True)

3) 使用jit(nogil=True)实现高效并发（多线程）：
GIL, Global Interpreter Lock，全局解释器锁，即使在多核心处理器上，使用GIL的解释器也只允许同一时间执行一个执行绪，常用的有CPython和Ruby MRI.
from concurrent.futures import ThreadPoolExecutor
@nb.jit(nopython=True, nogil=True)
def make_multi_task(kernel, n_thread):
    def func(length, *args):
        result = np.empty(length, dtype=np.float32)
        args = (result,) + args
        # 将每个线程接受的参数定义好
        chunk_size = (length + n_thread - 1)
        chunks = [[arg[i*chunk_size:(i+1)*chunk_size] for i in range(n_thread)] for i in range(n_thread)] for arg in args]
        # 利用ThreadPoolExecutor进行并发
        with ThreadPoolExecutor(max_workers=n_thread) as e:
            for _ in e.map(kernel, *chunks):
                pass
        return result
     return func
     
4）Numba的使用场景：
只支持了Python原生函数和部分NumPy函数
pandas是更高层次的封装，Numba其实不能理解它里面做了什么，所以无法对其加速
一些机器学习框架，如scikit-learn, tensorflow, pytorch等已经做了大量的优化，不适合再使用Numba做加速
不支持：try ... except 异常处理、with 语句、yield from
*args can only be a tuple, not a list
explicit **kwargs are not supported

5）还可以使用GPU进行加速，目前支持英伟达的CUDA和AMD的ROC

6）如果希望JIT能针对所有类型的参数进行运算，可以使用autojit，否则JIT所产生的函数只能针对指定类型的参数进行运算：
from numba import autojit
@autojit

7) 使用product扁平化多层嵌套循环：
from itertools import product

def find_twelve_v2(num_list1, num_list2, num_list3):
        for num1, num2, num3 in product(num_list1, num_list2, num_list3):
                if num1 + num2 + num3 == 12:
                        return num1, num2, num3
                        
 7）Numba加速例子：
 import sys
sys.path.insert(0, "C:/Users/quant")

import warnings
warnings.filterwarnings('ignore')

from IPython.display import Markdown

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline

import talib
pd.set_option('display.max_rows', None)    # Display all the pandas rows

import datetime
import numba as nb
import timeit
import time


data = pd.read_csv("############################.csv", index_col='id', nrows=2000)
df = data[['close', 'vol']]
print(df.head())

MA5 = talib.SMA(np.array(df['close']), timeperiod=5)
MA20 = talib.SMA(np.array(df['close']), timeperiod=20)

df['ma5'] = MA5
df['ma20'] = MA20
temp = np.zeros(len(df))
df['position'] = pd.Series(temp, index=df.index)
# LE_Price = 0    # DO NOT define global variables easily
# SE_Price = 0    # DO NOT define global variables easily
print(df.head(30))
print(df['position'].values)

df.reset_index(level=0, inplace=True)  # 将index时间戳变成column，以便转换成ndarray时可见
df3 = df[['id', 'close', 'ma5', 'ma20', 'position']]
print(df3.head())

dt = df3.replace(np.nan,0).values[:,1:]   # 小心处理NaN值变成0，Numba处理多维数组内的数据类型需要相同
print(dt)
print(type(dt))   # 此时dtype为object，Numba不支持此类型
len_dt = len(dt)
print(len_dt)
print(dt.dtype)
dt= dt.astype(np.float64)  # 将ndarray内的元素类型统一转换为float64
print(dt)
print(dt.dtype)

# MA Strategy
# start = datetime.datetime.now()
# dt1 = dt.copy()
@nb.jit(nopython=True, cache=True)
def func_nb(dt1):
    LE_Price = 0
    SE_Price = 0
    for i in range(len(dt1)):
        # Long Entry
        if (dt1[i,3] == 0) and (dt1[i,1] - dt1[i,2] > 0.5):
            dt1[i,3] = 1
            LE_Price = dt1[i,0]

        # Long Exit
        if (dt1[i,3] == 1) and (dt1[i,1] - dt1[i,2] < -0.5):
            dt1[i,3] = 0
            LE_Price = 0
            SE_Price = 0

        # Long Stoploss
        if (dt1[i,3] == 1) and (dt1[i,0] - LE_Price < -0.3):
            dt1[i,3] = 0
            LE_Price = 0
            SE_Price = 0

        # Short Entry
        if (dt1[i,3] == 0) and (dt1[i,1] - dt1[i,2] < -0.5):
            dt1[i,3] = -1.
            SE_Price = dt[i,0]

        # Short Exit
        if (dt1[i,3] == -1) and (dt1[i,1] - dt1[i,2] > 0.5):
            dt1[i,3] = 0.
            LE_Price = 0
            SE_Price = 0

        # Short Stoploss
        if (dt1[i,3] == -1) and (dt1[i,0] - SE_Price > 0.3):
            dt1[i,3] = 0
            LE_Price = 0
            SE_Price = 0
        
# runTime = datetime.datetime.now() - start
# print(runTime)
# %timeit func_nb()

start_time = time.time()
for i_time in range(100):
    func_nb(dt1=dt.copy())    # Numba cannot figure out global ndarray, we need transfer the copy of the global ndarray and rename it
print("time=%.6f" % (time.time() - start_time))

dt_pos = func_nb(dt1=dt.copy())
print(dt_pos)

df['pos'] = dt_pos
df['marketReturn'] = np.log(df['close']/df['close'].shift(1))
df['strategyReturn'] = df['marketReturn'] * df['pos']
print(df.head(100))

df['strategyReturn'].cumsum().plot()
 
 
 

